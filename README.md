# Microservice of Test Scrapper


## Требования к установке
```sh
1. устанавливаем poetry
2. копируем файл .env_example в .env и указываем валидные данные 
3. запускаем проект через командную строку poetry run python main.py
```

### .env example
```sh
SERVER_HOST='127.0.0.1'
SERVER_PORT=8007
DATABASE_URL="postgresql+psycopg2://login:password@host/db_name"

CORS_ALLOWED_ORIGINS='["http://localhost:8000", "http://127.0.0.1:8000"]'
```

## Проблемы
Я увидел следующие "подводные" камни:
1) Если список url большой, то их обработка занимает достаточное кол-во времени.
Возможное решение: самое простое , наверное, это асинхронно скрапить все url, для этого надо переписать код. Также можно использовать кеширования, чтобы повторно не собирать html ( только при условии, если он не поменялся)
2) Хранение в бд: в бд html занимает много места, надо бы продумать, что с этим сделать
3) Это касается безопастности: если я не ошибаюсь, то в html может быть внедрен вредоносный код (sql инъекции и тд)
Возможные решения: фильтровать и валидировать html, ну и можно сделать этот метод доступным только авторизированным пользователям
Как масштабировать:
Из вариантов на ум приходит только горизонтальное масштабирование, то есть сделать доп. сервисы и просто распределять нагрузку между ними
Чтобы было проще масштабировать можно использовать Docker, чтобы было проще развертывать сервис
